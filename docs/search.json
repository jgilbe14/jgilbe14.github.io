[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello! I am a graduate student in the statistics department at Virginia Tech. I received my Bachelor’s Degree in Statistics from CalPoly in San Luis Obispo, CA. I’m fascinated by the complexity of the world and the ubiquity of patterns, especially the hidden patterns in randomness. Statistics provides powerful tools to robustly quantify and analyze these patterns and to turn them into actionable insights.\nI have experience working in Python and R, and many other less significant statistical software packages such as JMP, Minitab and SAS."
  },
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Penguins, meet Quarto!",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "hello.html#meet-the-penguins",
    "href": "hello.html#meet-the-penguins",
    "title": "Penguins, meet Quarto!",
    "section": "Meet the penguins",
    "text": "Meet the penguins\n\nThe penguins data from the palmerpenguins package contains size measurements for 344 penguins from three species observed on three islands in the Palmer Archipelago, Antarctica.\nThe plot below shows the relationship between flipper and bill lengths of these penguins."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josiah Gilbert",
    "section": "",
    "text": "Litter Decomposition Study using Tidymodels\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2022\n\n\nJosiah Gilbert\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Litter Decomposition Study using Tidymodels",
    "section": "",
    "text": "For this project I utilized some of the tidymodels functionality to run classification models on data from a series of ecological experiments carried out across North America during the 1990’s. The experiments studied the chemical/nutritional composition of leaf litter as it decayed over time and in different climate and substrate regimes.\nFirst we need to load all of the necessary libraries for our analysis.\nThe data is stored in a number of different datasets and we need to read all of these in first and then combine them as necessary to be able to explore the data.\nI’m using three individual datasets\nWe can map the locations of the experiment sites using the leaflet package.\nNote that all of North America is included (extending towards the pole in Alaska) with additional sites in the Caribbean and Central America.\nI’m interested in exploring the relationship between the taxonomic family the leaf litter was sourced from and it’s nutritional composition. However, since there are 18 different families represented in our cleaned data some with only a few observation, I’m going to focus on the top five familes with the most observations in our dataset. We’ll determine which those familes are in the code below."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html#k-nearest-neighbors",
    "href": "posts/post-with-code/index.html#k-nearest-neighbors",
    "title": "Litter Decomposition Study using Tidymodels",
    "section": "K-nearest Neighbors",
    "text": "K-nearest Neighbors\nWe’ll using the classic K-nearest neighbors model. To fit a model in the tidyverse we specify the “recipe” which in our simple case is just the response and predictors and the data source. We then specify the model, including the engine (the package for the model) and the mode (classification in our case). We are interested in predicative accuracy, so we’ll use cross-validation to estimate the out-of-sample predicative accuracy.\n\nset.seed(452)\n\ntop_fam_nutrients <- nutrients %>%\n  filter(family %in% top_fams) %>%\n  mutate(\"family\" = as.character(family))\n\nfamily_recipe <- recipe(family ~ B + CA + CU + FE + K + MG + MN + P + ZN, data = top_fam_nutrients)\n\nknn_mod <- nearest_neighbor() %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"classification\")\n\nfamily_workflow_knn <- workflow() %>% \n  add_recipe(family_recipe) %>% \n  add_model(knn_mod)\n\nfamily_cvs <- vfold_cv(top_fam_nutrients, v = 10)\n\nfamily_workflow_knn %>% fit_resamples(family_cvs) %>% collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.689    10  0.0110 Preprocessor1_Model1\n2 roc_auc  hand_till  0.860    10  0.0119 Preprocessor1_Model1\n\n\nOur k-nearest neighbor’s model was able to successfully predict which of the five top families a given leaf litter sample came from about 69% of the time. Not terrible accuracy for a multiclass problem (as opposed to a binary classification problem), but still not very good. Let’s see if we can do better with some other kind of model."
  },
  {
    "objectID": "posts/post-with-code/index.html#trees",
    "href": "posts/post-with-code/index.html#trees",
    "title": "Litter Decomposition Study using Tidymodels",
    "section": "Trees",
    "text": "Trees\n\nDecision Trees\nWe’ll try a decision tree next. The process is very similar, and since we already specified a recipe when fitting our k-nearest neighbors model we’ll just reuse that recipe here. Again, we’ll cross-validate to find our estimated out-of-sample predictive accuracy.\n\nset.seed(214)\n\ndt_mod <- decision_tree() %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")\n\nfamily_workflow_dt <- workflow() %>% \n  add_recipe(family_recipe) %>% \n  add_model(dt_mod)\n\nfamily_workflow_dt %>% fit_resamples(family_cvs) %>% collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.622    10  0.0152 Preprocessor1_Model1\n2 roc_auc  hand_till  0.799    10  0.0106 Preprocessor1_Model1\n\n\nOur decision tree actually fared worse than the k-nearest neighbor’s model, with an estimated predictive accuracy of about 62%.\nWe can also plot our decision tree, which can show us which are the most important variables in classifying the family of the sample.\n\nfitted_family_tree <- fit(family_workflow_dt, data = top_fam_nutrients) %>% extract_fit_parsnip()\n\nrpart.plot(fitted_family_tree$fit, roundint = FALSE)\n\n\n\n\n\n\nBagged Trees\nNow let’s try a bagged tree. This bootstraps our data and then builds many different treees based on those different bootstraped samples and uses the overall prediction from all the trees to classify the data.\n\nset.seed(615)\n\nbag_tree_mod <- bag_tree() %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")\n\nfamily_workflow_bgt <- workflow() %>% \n  add_recipe(family_recipe) %>% \n  add_model(bag_tree_mod)\n\nfamily_workflow_bgt %>% fit_resamples(family_cvs) %>% collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.732    10 0.00887 Preprocessor1_Model1\n2 roc_auc  hand_till  0.899    10 0.00967 Preprocessor1_Model1\n\n\nWe see improvement over the decision tree and even our k-nearest neighbor’s model, with an estimated out-of-sample predicative accuracy of 73%.\n\n\nRandom Forest\nLet’s try a random forest next. A random forest also is built using bootstrapped samples from the orginal sample, like a bagged tree, but it builds different trees using different subsets of the possible predictors.\n\nset.seed(943)\n\nrf_mod <- rand_forest() %>% \n  set_engine(\"ranger\") %>% \n  set_mode(\"classification\")\n\nfamily_workflow_rf <- workflow() %>% \n  add_recipe(family_recipe) %>% \n  add_model(rf_mod)\n\nfamily_workflow_rf %>% fit_resamples(family_cvs) %>% collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.775    10 0.00850 Preprocessor1_Model1\n2 roc_auc  hand_till  0.928    10 0.00728 Preprocessor1_Model1\n\n\nOur random forest model has the best predictive accuracy of any of the models we’ve tested so far with an estimated out-of-sample predicative accuracy of 77.5%.\nTwo final methods we can try are Linear Discriminant Analysis and Quadratic Discriminant Analysis.\n\n\nLinear Discriminant Analysis\nI’m less familiar with how either LDA or QDA works so I’ll simply report the results.\n\nset.seed(121)\n\nlda_mod <- discrim_linear() %>%\n  set_engine(\"MASS\") %>%\n  set_mode(\"classification\")\n\nfamily_workflow_lda <- workflow() %>% \n  add_recipe(family_recipe) %>% \n  add_model(lda_mod)\n\nfamily_workflow_lda %>% fit_resamples(family_cvs) %>% collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.506    10  0.0177 Preprocessor1_Model1\n2 roc_auc  hand_till  0.774    10  0.0110 Preprocessor1_Model1\n\n\nOur worst model so far, our LDA model has an estimated out-of-sample predicative accuracy of just over 50%.\n\n\nQuadratic Discriminant Analysis\n\nset.seed(333)\n\nqda_mod <- discrim_quad() %>% \n             set_engine('MASS') %>% \n             set_mode('classification')\n\nfamily_workflow_qda <- workflow() %>% \n  add_recipe(family_recipe) %>% \n  add_model(qda_mod)\n\nfamily_workflow_qda %>% fit_resamples(family_cvs) %>% collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy multiclass 0.452    10  0.0141 Preprocessor1_Model1\n2 roc_auc  hand_till  0.729    10  0.0136 Preprocessor1_Model1\n\n\nRemarkably exceeding the LDA in lack of accuracy, our LDA model has an estimated out-of-sample predicative accuracy of 45%."
  }
]